{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d81f5c3-fdd4-4b65-bbcb-b852fc3a11ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-10T06:52:04.861962Z",
     "iopub.status.busy": "2022-11-10T06:52:04.861665Z",
     "iopub.status.idle": "2022-11-10T06:52:26.676814Z",
     "shell.execute_reply": "2022-11-10T06:52:26.676330Z",
     "shell.execute_reply.started": "2022-11-10T06:52:04.861931Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "659b878e68b8468d9b1e384a7b8db258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>4</td><td>application_1668061613914_0007</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-20-0-4-126.ap-south-1.compute.internal:20888/proxy/application_1668061613914_0007/\" class=\"emr-proxy-link\" emr-resource=\"j-3C4KSQDGDGNLV\n",
       "\" application-id=\"application_1668061613914_0007\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-20-0-4-248.ap-south-1.compute.internal:8042/node/containerlogs/container_1668061613914_0007_01_000001/livy\" >Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "An error occurred while calling o94.load.\n",
      ": java.lang.ClassNotFoundException: com.microsoft.sqlserver.jdbc.SQLServerDriver\n",
      "\tat java.net.URLClassLoader.findClass(URLClassLoader.java:387)\n",
      "\tat java.lang.ClassLoader.loadClass(ClassLoader.java:418)\n",
      "\tat java.lang.ClassLoader.loadClass(ClassLoader.java:351)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.DriverRegistry$.register(DriverRegistry.scala:46)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$1(JDBCOptions.scala:102)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$1$adapted(JDBCOptions.scala:102)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:102)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:38)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:32)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:355)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:325)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$3(DataFrameReader.scala:307)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:307)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:225)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py\", line 210, in load\n",
      "    return self._df(self._jreader.load())\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1305, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py\", line 111, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
      "    format(target_id, \".\", name), value)\n",
      "py4j.protocol.Py4JJavaError: An error occurred while calling o94.load.\n",
      ": java.lang.ClassNotFoundException: com.microsoft.sqlserver.jdbc.SQLServerDriver\n",
      "\tat java.net.URLClassLoader.findClass(URLClassLoader.java:387)\n",
      "\tat java.lang.ClassLoader.loadClass(ClassLoader.java:418)\n",
      "\tat java.lang.ClassLoader.loadClass(ClassLoader.java:351)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.DriverRegistry$.register(DriverRegistry.scala:46)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$1(JDBCOptions.scala:102)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$1$adapted(JDBCOptions.scala:102)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:102)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:38)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:32)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:355)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:325)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$3(DataFrameReader.scala:307)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:307)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:225)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11f2569c-5a8b-4d71-8a8a-2861845b8c8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-10T06:54:15.340735Z",
     "iopub.status.busy": "2022-11-10T06:54:15.340512Z",
     "iopub.status.idle": "2022-11-10T06:54:55.096048Z",
     "shell.execute_reply": "2022-11-10T06:54:55.095397Z",
     "shell.execute_reply.started": "2022-11-10T06:54:15.340712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>5</td><td>application_1668061613914_0008</td><td>pyspark</td><td>idle</td><td></td><td></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.jars': 's3://sjet-datamart-bucket/Jars/mssql-jdbc-6.1.0.jre8.jar'}, 'proxyUser': 'user_ayush_vaishnav', 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>2</td><td>application_1668061613914_0005</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://ip-20-0-4-126.ap-south-1.compute.internal:20888/proxy/application_1668061613914_0005/\" class=\"emr-proxy-link\" emr-resource=\"j-3C4KSQDGDGNLV\n",
       "\" application-id=\"application_1668061613914_0005\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-20-0-4-147.ap-south-1.compute.internal:8042/node/containerlogs/container_1668061613914_0005_01_000001/livy\" >Link</a></td><td></td></tr><tr><td>5</td><td>application_1668061613914_0008</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-20-0-4-126.ap-south-1.compute.internal:20888/proxy/application_1668061613914_0008/\" class=\"emr-proxy-link\" emr-resource=\"j-3C4KSQDGDGNLV\n",
       "\" application-id=\"application_1668061613914_0008\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-20-0-4-187.ap-south-1.compute.internal:8042/node/containerlogs/container_1668061613914_0008_01_000001/livy\" >Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\": {\n",
    "        \"spark.jars\": \"s3://sjet-datamart-bucket/Jars/mssql-jdbc-6.1.0.jre8.jar\"        \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1da8a78e-1305-407e-a92b-cc468403f488",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-10T07:28:45.366892Z",
     "iopub.status.busy": "2022-11-10T07:28:45.366678Z",
     "iopub.status.idle": "2022-11-10T07:28:46.116107Z",
     "shell.execute_reply": "2022-11-10T07:28:46.115641Z",
     "shell.execute_reply.started": "2022-11-10T07:28:45.366869Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "252fd012a08b4043a766ab0ddf526c70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GoldenRecordISPINC_fact = spark.read.format(\"jdbc\")\\\n",
    "        .option(\"url\", \"jdbc:sqlserver://10.150.72.22:1433;databaseName=CustomerHub;\")\\\n",
    "        .option(\"query\",\"SELECT * FROM dbo.GoldenRecordISPINC_fact where AlternateKey between '96231453' and '108260380' \")\\\n",
    "        .option(\"user\", \"dmbigdata\")\\\n",
    "        .option(\"password\", \"$p!Ce@bigData$db\")\\\n",
    "        .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\")\\\n",
    "        .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0252e11f-69ef-4754-942a-c3b3b7f24ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7326f8d5-e0d6-45ca-932a-d50ac3ab5c45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d153b310-58ae-4499-abbf-e388edd003aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c18ce1b8-f00e-4b65-885b-1b861ecc1db4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-10T07:28:48.971687Z",
     "iopub.status.busy": "2022-11-10T07:28:48.971471Z",
     "iopub.status.idle": "2022-11-10T07:45:04.477348Z",
     "shell.execute_reply": "2022-11-10T07:45:04.476878Z",
     "shell.execute_reply.started": "2022-11-10T07:28:48.971663Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ddbb206c5c48ba8af47631e46b7faf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GoldenRecordISPINC_fact.write.mode(\"append\").parquet(\n",
    "                \"s3://sjet-datamart-bucket/22-CustomerHub/GoldenRecordISPINC_fact/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399ff701-4cff-422c-b50c-d3b6bd75ab47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
